{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant API - Function Calling\n",
    "An assistant is a purpose-built AI that has specific instructions, leverages extra knowledge, and can call models and tools to perform tasks.\n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/function-calling\n",
    "\n",
    "https://cookbook.openai.com/examples/assistants_api_overview_python\n",
    "\n",
    "https://dev.to/esponges/build-the-new-openai-assistant-with-function-calling-52f5\n",
    "\n",
    "https://community.openai.com/t/function-calling-with-assistants-api/488259/2\n",
    "\n",
    "https://community.openai.com/t/function-calling-with-assistants-api/488259\n",
    "\n",
    "https://dev.to/airtai/function-calling-and-code-interpretation-with-openais-assistant-api-a-quick-and-simple-tutorial-5ce5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv('C:/Code_Apps/Learn-Generative-AI/03_chatgpt/.env'))\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defining for Function Calling\n",
    "import json\n",
    "\n",
    "def get_local_weather(city:str,unit:str=\"fahrenheit\")->str:\n",
    "    \"\"\"Giving current local cities temperature\"\"\"\n",
    "    if \"lahore\" in city.lower():\n",
    "        return json.dumps({\"city\":\"Lahore\",\"temperature\":\"51\",\"unit\":\"fahrenheit\"})\n",
    "    elif \"karachi\" in city.lower():\n",
    "        return json.dumps({\"city\":\"Karachi\",\"temperature\":\"24\",\"unit\":\"celsius\"})\n",
    "    elif \"gwadar\" in city.lower():\n",
    "        return json.dumps({\"city\":\"Gwadar\",\"temperature\":\"14\",\"unit\":\"fahrenheit\"})\n",
    "    else:\n",
    "        return json.dumps({\"city\":city,\"temperature\":\"Doesn't have given city data right now,but available in future\"})\n",
    "\n",
    "\n",
    "def get_nickname(city:str):\n",
    "    \"\"\"Get Nickname of a city\"\"\"\n",
    "    if \"lahore\" in city.lower():\n",
    "        return \"LHR\"\n",
    "    elif \"karachi\" in city.lower():\n",
    "        return \"KHI\"\n",
    "    elif \"gwadar\" in city.lower():\n",
    "        return \"GWD\"\n",
    "    else:\n",
    "        return city.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Assistant and Register functions to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_0Vo7m8tUDBxiRJf2CJ622l9s',\n",
       " 'created_at': 1707628844,\n",
       " 'description': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a weather bot. Please give information from the function provided.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'name': 'weather_assistant',\n",
       " 'object': 'assistant',\n",
       " 'tools': [ToolFunction(function=FunctionDefinition(name='getCurrentWeather', description='Get current the weather of the given city', parameters={'type': 'object', 'properties': {'city': {'type': 'string', 'description': 'The city or location e.g Faislabad,San Francisco'}, 'unit': {'type': 'string', 'enum': ['c', 'f']}}, 'required': ['city']}), type='function'),\n",
       "  ToolFunction(function=FunctionDefinition(name='getNickname', description='Get nickname of a city', parameters={'type': 'object', 'properties': {'city': {'type': 'string', 'description': 'The city or location e.g Faislabad,San Francisco'}}, 'required': ['city']}), type='function')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai.types.beta.assistant import Assistant\n",
    "\n",
    "assistant : Assistant = client.beta.assistants.create(\n",
    "    name=\"weather_assistant\",\n",
    "    instructions=\"You are a weather bot. Please give information from the function provided.\",\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    tools=[\n",
    "    {\n",
    "        \"type\":\"function\",\n",
    "        \"function\":{\n",
    "            \"name\":\"getCurrentWeather\",\n",
    "            \"description\": \"Get current the weather of the given city\",\n",
    "            \"parameters\":{\n",
    "                \"type\": \"object\",\n",
    "                \"properties\":{\n",
    "                    \"city\": {\"type\":\"string\",\"description\":\"The city or location e.g Faislabad,San Francisco\"},\n",
    "                    \"unit\": {\"type\": \"string\",\n",
    "                            \"enum\":[\"c\",\"f\"]\n",
    "                        }\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\":{\n",
    "            \"name\": \"getNickname\",\n",
    "            \"description\": \"Get nickname of a city\",\n",
    "            \"parameters\":{\n",
    "                \"type\": \"object\",\n",
    "                \"properties\":{\n",
    "                  \"city\": {\"type\":\"string\",\"description\":\"The city or location e.g Faislabad,San Francisco\"},\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(dict(assistant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_MTrEZeJ2GDdRDB9093EZUWGp',\n",
       " 'created_at': 1707628852,\n",
       " 'metadata': {},\n",
       " 'object': 'thread'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread : Thread = client.beta.threads.create()\n",
    "\n",
    "display(dict(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add Message To Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_V6tIKEb4drzQGhf69Mev8gb8',\n",
       " 'assistant_id': None,\n",
       " 'content': [MessageContentText(text=Text(annotations=[], value='What is the current Weather in Gwadar'), type='text')],\n",
       " 'created_at': 1707628858,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_MTrEZeJ2GDdRDB9093EZUWGp'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "message : ThreadMessage = client.beta.threads.messages.create(\n",
    "    role=\"user\",\n",
    "    content=\"What is the current Weather in Gwadar\",\n",
    "    thread_id=thread.id\n",
    ")\n",
    "dict(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_6r9RhwG7JfHzGdzwXgygndmT',\n",
       " 'assistant_id': 'asst_0Vo7m8tUDBxiRJf2CJ622l9s',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1707628862,\n",
       " 'expires_at': 1707629462,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a weather bot. Please give information from the function provided.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_MTrEZeJ2GDdRDB9093EZUWGp',\n",
       " 'tools': [ToolAssistantToolsFunction(function=FunctionDefinition(name='getCurrentWeather', description='Get current the weather of the given city', parameters={'type': 'object', 'properties': {'city': {'type': 'string', 'description': 'The city or location e.g Faislabad,San Francisco'}, 'unit': {'type': 'string', 'enum': ['c', 'f']}}, 'required': ['city']}), type='function'),\n",
       "  ToolAssistantToolsFunction(function=FunctionDefinition(name='getNickname', description='Get nickname of a city', parameters={'type': 'object', 'properties': {'city': {'type': 'string', 'description': 'The city or location e.g Faislabad,San Francisco'}}, 'required': ['city']}), type='function')],\n",
       " 'usage': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ToolAssistantToolsFunction(function=FunctionDefinition(name='getCurrentWeather', description='Get current the weather of the given city', parameters={'type': 'object', 'properties': {'city': {'type': 'string', 'description': 'The city or location e.g Faislabad,San Francisco'}, 'unit': {'type': 'string', 'enum': ['c', 'f']}}, 'required': ['city']}), type='function'),\n",
       " ToolAssistantToolsFunction(function=FunctionDefinition(name='getNickname', description='Get nickname of a city', parameters={'type': 'object', 'properties': {'city': {'type': 'string', 'description': 'The city or location e.g Faislabad,San Francisco'}}, 'required': ['city']}), type='function')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "run : Run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# cancel_run = client.beta.threads.runs.cancel(\n",
    "#   thread_id=thread.id,\n",
    "#   run_id=run.id\n",
    "# )\n",
    "\n",
    "display(dict(run))\n",
    "display(run.tools)\n",
    "# run_vLpWiqcN6hX4GmXJgdBOVt9U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Life Cycle\n",
    "\n",
    "![ALT TEXT](https://raw.githubusercontent.com/panaverse/learn-generative-ai/788f968387b0ad38bc379c3a4718400e8e42948d/03_chatgpt/08_assistants_function_calling/diagram.png)\n",
    "\n",
    "### Status Definition\n",
    "\n",
    "https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n",
    "\n",
    "##### queued:\n",
    "\n",
    "When Runs are first created or when you complete the required_action, they are moved to a queued status. They should almost immediately move to in_progress.\n",
    "\n",
    "##### in_progress:\n",
    "\n",
    "While `in_progress`, the Assistant uses the model and tools to perform steps. You can view progress being made by the Run by examining the Run Steps.\n",
    "\n",
    "##### completed:\n",
    "\n",
    "The Run successfully completed! You can now view all Messages the Assistant added to the Thread, and all the steps the Run took. You can also continue the conversation by adding more user Messages to the Thread and creating another Run.\n",
    "\n",
    "##### requires_action:\n",
    "\n",
    "When using the Function calling tool, the Run will move to a required_action state once the model determines the names and arguments of the functions to be called. You must then run those functions and submit the outputs before the run proceeds. If the outputs are not provided before the expires_at timestamp passes (roughly 10 mins past creation), the run will move to an expired status.\n",
    "\n",
    "##### expired:\n",
    "\n",
    "This happens when the function calling outputs were not submitted before expires_at and the run expires. Additionally, if the runs take too long to execute and go beyond the time stated in expires_at, our systems will expire the run.\n",
    "\n",
    "##### cancelling:\n",
    "\n",
    "You can attempt to cancel an in_progress run using the Cancel Run endpoint. Once the attempt to cancel succeeds, status of the Run moves to cancelled. Cancellation is attempted but not guaranteed. cancelled Run was successfully cancelled.\n",
    "\n",
    "##### failed:\n",
    "\n",
    "You can view the reason for the failure by looking at the last_error object in the Run. The timestamp for the failure will be recorded under failed_at.\n",
    "\n",
    "### Polling for updates\n",
    "In order to keep the status of your run up to date, you will have to periodically retrieve the Run object. You can check the status of the run each time you retrieve the object to determine what your application should do next. We plan to add support for streaming to make this simpler in the near future.\n",
    "\n",
    "#### Thread locks\n",
    "When a Run is in_progress and not in a terminal state, the Thread is locked. This means that:\n",
    "\n",
    "New Messages cannot be added to the Thread.\n",
    "New Runs cannot be created on the Thread.\n",
    "\n",
    "\n",
    "### Run Steps\n",
    "![ALT TEXT](https://raw.githubusercontent.com/panaverse/learn-generative-ai/788f968387b0ad38bc379c3a4718400e8e42948d/03_chatgpt/08_assistants_function_calling/diagram-2.png)\n",
    "\n",
    "\n",
    "Most of the interesting detail in the Run Step object lives in the step_details field. There can be two types of step details:\n",
    "\n",
    "1. message_creation: This Run Step is created when the Assistant creates a Message on the Thread.\n",
    "2. tool_calls: This Run Step is created when the Assistant calls a tool. Details around this are covered in the relevant sections of the Tools guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"getCurrentWeather\": get_local_weather,\n",
    "    \"getNickname\": get_nickname\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed .....\n",
      "user: What is the current Weather in Gwadar\n",
      "assistant: The current weather in Gwadar is 14°F.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def show_json(message, obj):\n",
    "    display(message, json.loads(obj.model_dump_json()))\n",
    "\n",
    "while True:\n",
    "\n",
    "    # runStatus = checkStatus(run.id,thread.id)\n",
    "    runStatus = client.beta.threads.runs.retrieve(run_id=run.id,thread_id=thread.id)\n",
    "    print(runStatus.status ,'.....')\n",
    "\n",
    "    if runStatus.status == \"requires_action\":\n",
    "        if runStatus.required_action.submit_tool_outputs and runStatus.required_action.submit_tool_outputs.tool_calls:\n",
    "            # print(\"toolCalls present:\")\n",
    "            toolcalls = runStatus.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "\n",
    "        for tools in toolcalls:\n",
    "            # print('tools are: ',tools)\n",
    "            # print('tool ids are: ',tools.id)\n",
    "            function_name = tools.function.name\n",
    "            function_args = json.loads(tools.function.arguments)\n",
    "            function_to_call = available_functions[tools.function.name]\n",
    "            # print(function_to_call.__name__)\n",
    "            if function_name in available_functions:\n",
    "                if function_to_call.__name__ == \"get_local_weather\":\n",
    "                    # print('gettin nickweather')\n",
    "                    response = function_to_call(\n",
    "                        city=function_args['city'],\n",
    "                        unit=function_args.get('unit')\n",
    "                    )\n",
    "                    # After calling function, response appended\n",
    "                    tool_outputs.append({\n",
    "                        \"tool_call_id\":tools.id,\n",
    "                        \"output\":response\n",
    "                        })\n",
    "                    # print(tool_outputs)\n",
    "\n",
    "                elif function_to_call.__name__ == \"get_nickname\":\n",
    "                    # print('gettin nickname')\n",
    "                    response = function_to_call(\n",
    "                        city=function_args.get('city')\n",
    "                    )\n",
    "                    tool_outputs.append({\n",
    "                        \"tool_call_id\":tools.id,\n",
    "                        \"output\":response\n",
    "                    })\n",
    "\n",
    "                # print(tool_outputs)\n",
    "        \n",
    "        client.beta.threads.runs.submit_tool_outputs(\n",
    "            run_id=run.id,\n",
    "            thread_id=thread.id,\n",
    "            tool_outputs=tool_outputs\n",
    "        )\n",
    "\n",
    "    elif runStatus.status == 'completed':\n",
    "        AllMessages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        for message in reversed(AllMessages.data):\n",
    "            print(f\"{message.role}: {message.content[0].text.value}\")\n",
    "            # print(f\"Message:{message.content[0].text.value} \")\n",
    "        break\n",
    "\n",
    "\n",
    "    elif runStatus.status == 'failed':\n",
    "        print('Run status failed')\n",
    "        break\n",
    "\n",
    "    elif runStatus.status in ['queued','in_progress']:\n",
    "        print(f\"Run is {run.status}. Waiting...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    else:\n",
    "        print(\"Unexpected Error\")\n",
    "        print(run.status)\n",
    "        break\n",
    "                \n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
